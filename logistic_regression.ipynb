{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "import numpy as np\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark as ps\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "import warnings\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def init_spark():\n",
    "    print(\"initializing spark...\")\n",
    "    try:\n",
    "        sc = ps.SparkContext('local[*]')\n",
    "        sqlContext = SQLContext(sc)\n",
    "        print(\"Just created a SparkContext\")\n",
    "    except ValueError:\n",
    "        warnings.warn(\"SparkContext already exists in this scope\")\n",
    "    spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "def read_file(fileName):\n",
    "    print(\"reading csv file...\")\n",
    "    df=spark.read.csv(fileName,sep=\",\",inferSchema=True,header=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pre_process(df):\n",
    "    print(\"preprocessing...\")\n",
    "    df.count()\n",
    "    df1=df.withColumnRenamed('_c0',\"id\").withColumnRenamed('_c1','label').withColumnRenamed('_c2','tweet')\n",
    "    df2 = df1.withColumn('tweet', regexp_replace('tweet', '[^a-z0-9A-Z`~!@#$%&<>?., ]', ''))\n",
    "    df3 = df2.withColumn('tweet', regexp_replace('tweet', '[0-9`~!@#$%&<>?,\\']', ''))\n",
    "    df4 = df3.withColumn('tweet', regexp_replace('tweet', 'http://*.*.com', ''))\n",
    "    df5 = df4.withColumn('tweet', regexp_replace('tweet', 'www.*.com', ''))\n",
    "    df6 = df5.withColumn('tweet', regexp_replace('tweet', '\\.', ''))\n",
    "    tokenizer=Tokenizer(inputCol=\"tweet\",outputCol=\"words\")\n",
    "    wordData=tokenizer.transform(df6)\n",
    "    remover=StopWordsRemover(inputCol=\"words\",outputCol=\"word_clean\")\n",
    "    word_clean_data=remover.transform(wordData)\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "    count=CountVectorizer(inputCol=\"word_clean\",outputCol=\"rawFeatures\")\n",
    "    model=count.fit(word_clean_data)\n",
    "    featurizedData=model.transform(word_clean_data)\n",
    "    idf=IDF(inputCol=\"rawFeatures\",outputCol=\"features\")\n",
    "    idfModel=idf.fit(featurizedData)\n",
    "    rescaledData=idfModel.transform(featurizedData)\n",
    "    return rescaledData\n",
    "\n",
    "\n",
    "def train_test_split(df,train=0.7,test=0.3):\n",
    "    print(\"splitting dataset...\")\n",
    "    seed=0\n",
    "    trainDf,testDf=df.randomSplit([train,test],seed)\n",
    "    trainDf.count()\n",
    "    testDf.count()\n",
    "    return trainDf,testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(train_data,test_data,maxIt=15,nFolds=8):\n",
    "    print(\"................................................................................................\")\n",
    "    print(\"Using logistic regression model with test_data...\")\n",
    "    d1 = {}\n",
    "    d2 = {}\n",
    "    \n",
    "    lr = LogisticRegression(maxIter=maxIt)\n",
    "    paramGrid_lr = ParamGridBuilder().build()\n",
    "    \n",
    "    crossval_lr = CrossValidator(estimator=lr,estimatorParamMaps=paramGrid_lr,evaluator=BinaryClassificationEvaluator(),numFolds=nFolds)\n",
    "    cvModel_lr = crossval_lr.fit(train_data)\n",
    "    best_model_lr = cvModel_lr.bestModel.summary\n",
    "    \n",
    "    report = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"label\",metricName=\"areaUnderROC\")\n",
    "    p1 = report.evaluate(best_model_lr.predictions)\n",
    "    \n",
    "    pred_lr = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol=\"label\",metricName=\"f1\")\n",
    "    p2 = pred_lr.evaluate(best_model_lr.predictions)\n",
    "    \n",
    "    pred_lr = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol=\"label\",metricName=\"accuracy\")\n",
    "    p3 = pred_lr.evaluate(best_model_lr.predictions)\n",
    "    \n",
    "    train_fit_lr = best_model_lr.predictions.select('label','prediction')\n",
    "    print(train_fit_lr.groupBy('label','prediction').count().show())\n",
    "    \n",
    "    d1['ROC'] = p1\n",
    "    d1['F1'] = p2\n",
    "    d1['Accuracy'] = p3\n",
    "    \n",
    "    predictions_lr = cvModel_lr.transform(test_data)\n",
    "    print(predictions_lr.groupBy('label','prediction').count().show())\n",
    "    \n",
    "    my_eval_lr = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "    p4=my_eval_lr.evaluate(predictions_lr)\n",
    "    \n",
    "    my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "    p5=my_mc_lr.evaluate(predictions_lr)\n",
    "    \n",
    "    my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "    p6=my_mc_lr.evaluate(predictions_lr)\n",
    "    \n",
    "    d2['ROC'] = p4\n",
    "    d2['F1']= p5\n",
    "    d2['Accuracy'] = p6\n",
    "    print(\"................................................................................................\")\n",
    "    return d1,d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing spark...\n",
      "reading csv file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: SparkContext already exists in this scope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n",
      "splitting dataset...\n"
     ]
    }
   ],
   "source": [
    "init_spark()\n",
    "df=read_file(\"twitter.csv\")\n",
    "df=pre_process(df)\n",
    "train_data,test_data=train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................\n",
      "Using logistic regression model with test_data...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|20736|\n",
      "|  1.0|       1.0| 1568|\n",
      "|  1.0|       0.0|    5|\n",
      "|  0.0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  278|\n",
      "|    0|       0.0| 8794|\n",
      "|    1|       1.0|  398|\n",
      "|    0|       1.0|  182|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "................................................................................................\n",
      "{'ROC': 0.9983865687373251, 'F1': 0.9997309040827688, 'Accuracy': 0.9997310623038996}\n",
      "{'ROC': 0.7842405520572941, 'F1': 0.9523414836303357, 'Accuracy': 0.9506468904290225}\n",
      "Time elapsed: 11.502746252218882  mins.\n",
      "................................................................................................\n",
      "Using logistic regression model with test_data...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|20736|\n",
      "|  1.0|       1.0| 1568|\n",
      "|  1.0|       0.0|    5|\n",
      "|  0.0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  278|\n",
      "|    0|       0.0| 8794|\n",
      "|    1|       1.0|  398|\n",
      "|    0|       1.0|  182|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "................................................................................................\n",
      "{'ROC': 0.9983865687373251, 'F1': 0.9997309040827688, 'Accuracy': 0.9997310623038996}\n",
      "{'ROC': 0.7842405520572941, 'F1': 0.9523414836303357, 'Accuracy': 0.9506468904290225}\n",
      "Time elapsed: 15.933311609427134  mins.\n",
      "................................................................................................\n",
      "Using logistic regression model with test_data...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|20736|\n",
      "|  1.0|       1.0| 1568|\n",
      "|  1.0|       0.0|    5|\n",
      "|  0.0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  278|\n",
      "|    0|       0.0| 8794|\n",
      "|    1|       1.0|  398|\n",
      "|    0|       1.0|  182|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "................................................................................................\n",
      "{'ROC': 0.9983865687373251, 'F1': 0.9997309040827688, 'Accuracy': 0.9997310623038996}\n",
      "{'ROC': 0.7842405520572941, 'F1': 0.9523414836303357, 'Accuracy': 0.9506468904290225}\n",
      "Time elapsed: 23.17492468357086  mins.\n",
      "................................................................................................\n",
      "Using logistic regression model with test_data...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       0.0|20736|\n",
      "|  1.0|       1.0| 1568|\n",
      "|  1.0|       0.0|    5|\n",
      "|  0.0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  278|\n",
      "|    0|       0.0| 8794|\n",
      "|    1|       1.0|  398|\n",
      "|    0|       1.0|  182|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "................................................................................................\n",
      "{'ROC': 0.9983865687373251, 'F1': 0.9997309040827688, 'Accuracy': 0.9997310623038996}\n",
      "{'ROC': 0.7842405520572941, 'F1': 0.9523414836303357, 'Accuracy': 0.9506468904290225}\n",
      "Time elapsed: 25.667572661240897  mins.\n",
      "................................................................................................\n",
      "................................................................................................\n",
      "Train summary for varying no of numFolds:\n",
      "Nfolds        Accuracy\n",
      "5          0.9997310623038996\n",
      "10          0.9997310623038996\n",
      "15          0.9997310623038996\n",
      "20          0.9997310623038996\n",
      "................................................................................................\n",
      "................................................................................................\n",
      "Test summary for varying no of numFolds:\n",
      "Nfolds        Accuracy\n",
      "5          0.9506468904290225\n",
      "10          0.9506468904290225\n",
      "15          0.9506468904290225\n",
      "20          0.9506468904290225\n",
      "................................................................................................\n",
      "................................................................................................\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "d={}\n",
    "e={}\n",
    "#training the model and checking its accuracy\n",
    "#for varying values of numFolds\n",
    "for i in range(5,25,5):\n",
    "    start=time.time()\n",
    "    train_summary,test_summary=logistic_regression(train_data,test_data,20,i)\n",
    "    print(train_summary)\n",
    "    print(test_summary)\n",
    "    d[i]=train_summary\n",
    "    e[i]=test_summary\n",
    "    elapsed=time.time()-start\n",
    "    print(\"Time elapsed:\",elapsed/60,\" mins.\")\n",
    "\n",
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")\n",
    "print(\"Train summary for varying no of numFolds:\")\n",
    "print(\"Nfolds        Accuracy\")\n",
    "for nf,acc in d.items():\n",
    "    print(nf,\"        \",acc['Accuracy'])\n",
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")\n",
    "print(\"Test summary for varying no of numFolds:\")\n",
    "print(\"Nfolds        Accuracy\")\n",
    "for nf,acc in e.items():\n",
    "    print(nf,\"        \",acc['Accuracy'])\n",
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting dataset...\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data=train_test_split(df,0.5,0.5)\n",
    "#checking accuracy of the model when\n",
    "#the train and test data is split 50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................\n",
      "Using logistic regression model with test_data...\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 1127|\n",
      "|  0.0|       0.0|14919|\n",
      "|  1.0|       0.0|    6|\n",
      "|  0.0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|  513|\n",
      "|    0|       0.0|14516|\n",
      "|    1|       1.0|  603|\n",
      "|    0|       1.0|  277|\n",
      "+-----+----------+-----+\n",
      "\n",
      "None\n",
      "................................................................................................\n",
      "{'ROC': 0.9973186503363629, 'F1': 0.9995634988117358, 'Accuracy': 0.9995639444340622}\n",
      "{'ROC': 0.7607987539878277, 'F1': 0.9503425733861336, 'Accuracy': 0.9476033989194182}\n",
      "Time elapsed: 13.044400397936503  mins.\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "train_summary,test_summary=logistic_regression(train_data,test_data)\n",
    "print(train_summary)\n",
    "print(test_summary)\n",
    "elapsed=time.time()-start\n",
    "print(\"Time elapsed:\",elapsed/60,\" mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")\n",
    "print(\"Train summary for varying no of numFolds:\")\n",
    "print(\"Nfolds        Accuracy\")\n",
    "for nf,acc in d.items():\n",
    "    print(nf,\"        \",acc['Accuracy'])\n",
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")\n",
    "print(\"Test summary for varying no of numFolds:\")\n",
    "print(\"Nfolds        Accuracy\")\n",
    "for nf,acc in e.items():\n",
    "    print(nf,\"        \",acc['Accuracy'])\n",
    "print(\"................................................................................................\")\n",
    "print(\"................................................................................................\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
